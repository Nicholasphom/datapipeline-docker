# datapipeline-docker
This Docker Compose configuration is designed to set up a development environment for Hadoop, Spark, and Apache Airflow. It orchestrates various services and containers, making it easier to run and manage these components together.
This is meant for you to run a sanatized develop enviorment and is a work in progress
