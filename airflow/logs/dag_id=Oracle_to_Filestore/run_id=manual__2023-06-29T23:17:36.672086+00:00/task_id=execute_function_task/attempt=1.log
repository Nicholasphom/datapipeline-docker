[2023-06-29T23:17:37.271+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-06-29T23:17:36.672086+00:00 [queued]>
[2023-06-29T23:17:37.276+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-06-29T23:17:36.672086+00:00 [queued]>
[2023-06-29T23:17:37.276+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-29T23:17:37.283+0000] {taskinstance.py:1327} INFO - Executing <Task(_PythonDecoratedOperator): execute_function_task> on 2023-06-29 23:17:36.672086+00:00
[2023-06-29T23:17:37.287+0000] {standard_task_runner.py:57} INFO - Started process 4617 to run task
[2023-06-29T23:17:37.289+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Oracle_to_Filestore', 'execute_function_task', 'manual__2023-06-29T23:17:36.672086+00:00', '--job-id', '600', '--raw', '--subdir', 'DAGS_FOLDER/Python-Delta-Lake/Dags/SparkOracle2FileStoreDag.py', '--cfg-path', '/tmp/tmpml_hpvql']
[2023-06-29T23:17:37.291+0000] {standard_task_runner.py:85} INFO - Job 600: Subtask execute_function_task
[2023-06-29T23:17:37.317+0000] {task_command.py:410} INFO - Running <TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-06-29T23:17:36.672086+00:00 [running]> on host a35364001907
[2023-06-29T23:17:37.359+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='phomsophaN@saccounty.net' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Oracle_to_Filestore' AIRFLOW_CTX_TASK_ID='execute_function_task' AIRFLOW_CTX_EXECUTION_DATE='2023-06-29T23:17:36.672086+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-29T23:17:36.672086+00:00'
[2023-06-29T23:17:37.359+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-06-29T23:17:37.360+0000] {logging_mixin.py:149} INFO - setting up configured spark connection Cluster
[2023-06-29T23:17:37.360+0000] {logging_mixin.py:149} INFO - Initializing support for delta lake spark context
[2023-06-29T23:17:40.336+0000] {logging_mixin.py:149} INFO - Returning Spark Context
[2023-06-29T23:17:40.337+0000] {client.py:192} INFO - Instantiated <InsecureClient(url='http://namenode:50070')>.
[2023-06-29T23:17:40.337+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:17:40.350+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:17:40.350+0000] {logging_mixin.py:149} INFO - HDFS Detected and Connected
[2023-06-29T23:17:40.350+0000] {logging_mixin.py:149} INFO - Spark Connection check - session found
[2023-06-29T23:17:40.905+0000] {logging_mixin.py:149} INFO - Attempt to read Msql Table by query: select * from DeltaLake.OracleTablesLog
        where OracleRows < 1000000 AND OracleRows > 10000 AND OracleSizeInMB < 2500 AND CountyFilter IS NOT NULL and PrimaryKeyColumn !=''
[2023-06-29T23:17:44.235+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.236+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.240+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.241+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.241+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.244+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.245+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T23:17:44.253+0000] {SparkOracle2FileStore.py:62} INFO - ['PR_LRS.FOSTER_FAM_AGNC', 'PR_LRS.EBT_EXPG_EXCPT', 'PR_LRS.ENCL_ESTIMATE', 'PR_LRS.UNIT', 'PR_LRS.IEVS_SAVE_EXCEPT', 'PR_LRS.WTW_24_MONTH_SIGN_DATE', 'PR_LRS.RULES_ADMIN', 'PR_LRS.COUNTY_PARAMTR_ADMIN_HST', 'PR_LRS.C4Y_PREG', 'PR_LRS.IEVS_PRISON_MATCH', 'PR_LRS.ORG_ACCT', 'PR_LRS.TRAIN_PGM', 'PR_LRS.IFD_SSI', 'PR_LRS.C4Y_PERS_NON_COMPL', 'PR_LRS.POS', 'PR_LRS.ADH_SUMM', 'PR_LRS.WDTIP_PGM_PARTICPTN', 'PR_LRS.HEAR_SUMM', 'PR_LRS.WDTIP_ALERT', 'PR_LRS.IHSS_REFRL', 'PR_LRS.SFIS_COUNTY_INFO', 'PR_LRS.STAFF', 'PR_LRS.MEDS_ALERT_CONFIG', 'PR_LRS.BATCH_JOB', 'PR_LRS.IHSS_CASE', 'PR_LRS.RULES_ADMIN_HST', 'PR_LRS.TAX_INTRCPT', 'PR_LRS.WTW_24_MONTH_SIGN_DATE_HST', 'PR_LRS.COUNTY_PARAMTR_ADMIN', 'PR_LRS.OCAT', 'PR_LRS.WDTIP_EXCEED_CLOCK', 'PR_LRS.AUTO_ACTN', 'PR_LRS.IFD_DUPL_DETL', 'PR_LRS.EBT_FRAUD_ACTIV', 'PR_LRS.GA_GR_TIME_LIMIT', 'PR_LRS.GRP_HOMES', 'PR_LRS.ASSET_VERIF', 'PR_LRS.FUND_CODE_MAP', 'PR_LRS.C4Y_OTHER_PGM_ASSIST', 'PR_LRS.IEVS_FF_MEDS', 'PR_LRS.COLLAB_CONTRACT', 'PR_LRS.WDTIP_APPRCH_CLOCK', 'PR_LRS.EXTRNL_STAFF_COUNTY_STAT', 'PR_LRS.VEND_IDENTIF', 'PR_LRS.OCAT_PERS', 'PR_LRS.MEDS_ALERT_CONFIG_HST', 'PR_LRS.WPR_SAMPLE_CASE', 'PR_LRS.PERS_TIME_TRACK_DETL']
[2023-06-29T23:17:44.255+0000] {SparkOracle2FileStore.py:80} INFO - processing 1 out of 48
[2023-06-29T23:17:44.255+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.FOSTER_FAM_AGNC
[2023-06-29T23:17:44.255+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:17:46.537+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.FOSTER_FAM_AGNC
[2023-06-29T23:17:46.537+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:17:47.663+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:17:48.215+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:17:48.215+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:17:49.609+0000] {SparkOracle2FileStore.py:103} INFO - 34262
[2023-06-29T23:17:49.609+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:17:50.770+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/FOSTER_FAM_AGNC exists...
[2023-06-29T23:17:50.770+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:17:50.779+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:17:50.780+0000] {client.py:320} INFO - Fetching status for '/dev/FOSTER_FAM_AGNC'.
[2023-06-29T23:17:50.784+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:17:50.784+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:17:52.519+0000] {SparkOracle2FileStore.py:126} INFO - read dir table should not fail and go in here...
[2023-06-29T23:17:59.699+0000] {SparkOracle2FileStore.py:139} INFO - no rows to upsert on table FOSTER_FAM_AGNC
[2023-06-29T23:18:02.927+0000] {SparkOracle2FileStore.py:143} INFO - Updating rows on table FOSTER_FAM_AGNC
[2023-06-29T23:18:13.715+0000] {SparkOracle2FileStore.py:157} INFO - no rows to delete on table FOSTER_FAM_AGNC
[2023-06-29T23:18:13.715+0000] {SparkOracle2FileStore.py:165} INFO - Table Processing complete for PR_LRS.FOSTER_FAM_AGNC
[2023-06-29T23:18:13.716+0000] {SparkOracle2FileStore.py:80} INFO - processing 2 out of 48
[2023-06-29T23:18:13.716+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.EBT_EXPG_EXCPT
[2023-06-29T23:18:13.716+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:18:14.811+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.EBT_EXPG_EXCPT
[2023-06-29T23:18:14.811+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:18:15.855+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:18:16.371+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:18:16.372+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:18:17.696+0000] {SparkOracle2FileStore.py:103} INFO - 316506
[2023-06-29T23:18:17.696+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:18:19.072+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/EBT_EXPG_EXCPT exists...
[2023-06-29T23:18:19.072+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:18:19.080+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:18:19.080+0000] {client.py:320} INFO - Fetching status for '/dev/EBT_EXPG_EXCPT'.
[2023-06-29T23:18:19.084+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:18:19.084+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:18:19.174+0000] {SparkOracle2FileStore.py:126} INFO - read dir table should not fail and go in here...
[2023-06-29T23:18:45.813+0000] {SparkOracle2FileStore.py:139} INFO - no rows to upsert on table EBT_EXPG_EXCPT
[2023-06-29T23:19:09.657+0000] {SparkOracle2FileStore.py:143} INFO - Updating rows on table EBT_EXPG_EXCPT
[2023-06-29T23:20:03.627+0000] {SparkOracle2FileStore.py:157} INFO - no rows to delete on table EBT_EXPG_EXCPT
[2023-06-29T23:20:03.628+0000] {SparkOracle2FileStore.py:165} INFO - Table Processing complete for PR_LRS.EBT_EXPG_EXCPT
[2023-06-29T23:20:03.629+0000] {SparkOracle2FileStore.py:80} INFO - processing 3 out of 48
[2023-06-29T23:20:03.629+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.ENCL_ESTIMATE
[2023-06-29T23:20:03.629+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:20:04.697+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.ENCL_ESTIMATE
[2023-06-29T23:20:04.697+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:20:05.985+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:20:06.511+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:20:06.511+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:20:07.594+0000] {SparkOracle2FileStore.py:103} INFO - 25979
[2023-06-29T23:20:07.594+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:20:08.745+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/ENCL_ESTIMATE exists...
[2023-06-29T23:20:08.745+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:20:08.755+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:20:08.755+0000] {client.py:320} INFO - Fetching status for '/dev/ENCL_ESTIMATE'.
[2023-06-29T23:20:08.760+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:20:08.760+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:20:08.833+0000] {SparkOracle2FileStore.py:126} INFO - read dir table should not fail and go in here...
[2023-06-29T23:20:10.989+0000] {SparkOracle2FileStore.py:139} INFO - no rows to upsert on table ENCL_ESTIMATE
[2023-06-29T23:20:12.766+0000] {SparkOracle2FileStore.py:143} INFO - Updating rows on table ENCL_ESTIMATE
[2023-06-29T23:20:18.465+0000] {SparkOracle2FileStore.py:157} INFO - no rows to delete on table ENCL_ESTIMATE
[2023-06-29T23:20:18.465+0000] {SparkOracle2FileStore.py:165} INFO - Table Processing complete for PR_LRS.ENCL_ESTIMATE
[2023-06-29T23:20:18.465+0000] {SparkOracle2FileStore.py:80} INFO - processing 4 out of 48
[2023-06-29T23:20:18.466+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.UNIT
[2023-06-29T23:20:18.466+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:20:19.699+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.UNIT
[2023-06-29T23:20:19.699+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:20:21.075+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:20:21.618+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:20:21.619+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:20:22.961+0000] {SparkOracle2FileStore.py:103} INFO - 42879
[2023-06-29T23:20:22.961+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:20:24.124+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/UNIT exists...
[2023-06-29T23:20:24.125+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:20:24.132+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:20:24.133+0000] {client.py:320} INFO - Fetching status for '/dev/UNIT'.
[2023-06-29T23:20:24.137+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:20:24.138+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:20:24.212+0000] {SparkOracle2FileStore.py:126} INFO - read dir table should not fail and go in here...
[2023-06-29T23:20:28.502+0000] {SparkOracle2FileStore.py:139} INFO - no rows to upsert on table UNIT
[2023-06-29T23:20:31.536+0000] {SparkOracle2FileStore.py:143} INFO - Updating rows on table UNIT
[2023-06-29T23:20:38.642+0000] {SparkOracle2FileStore.py:157} INFO - no rows to delete on table UNIT
[2023-06-29T23:20:38.642+0000] {SparkOracle2FileStore.py:165} INFO - Table Processing complete for PR_LRS.UNIT
[2023-06-29T23:20:38.643+0000] {SparkOracle2FileStore.py:80} INFO - processing 5 out of 48
[2023-06-29T23:20:38.643+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IEVS_SAVE_EXCEPT
[2023-06-29T23:20:38.643+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:20:39.780+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IEVS_SAVE_EXCEPT
[2023-06-29T23:20:39.780+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:20:40.890+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:20:41.450+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:20:41.450+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:20:42.938+0000] {SparkOracle2FileStore.py:103} INFO - 397776
[2023-06-29T23:20:42.938+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:20:44.610+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/IEVS_SAVE_EXCEPT exists...
[2023-06-29T23:20:44.610+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:20:44.618+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:20:44.618+0000] {client.py:320} INFO - Fetching status for '/dev/IEVS_SAVE_EXCEPT'.
[2023-06-29T23:20:44.621+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:20:44.622+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:20:44.695+0000] {SparkOracle2FileStore.py:126} INFO - read dir table should not fail and go in here...
[2023-06-29T23:21:19.170+0000] {SparkOracle2FileStore.py:139} INFO - no rows to upsert on table IEVS_SAVE_EXCEPT
[2023-06-29T23:22:20.585+0000] {SparkOracle2FileStore.py:143} INFO - Updating rows on table IEVS_SAVE_EXCEPT
[2023-06-29T23:23:53.779+0000] {SparkOracle2FileStore.py:157} INFO - no rows to delete on table IEVS_SAVE_EXCEPT
[2023-06-29T23:23:53.780+0000] {SparkOracle2FileStore.py:165} INFO - Table Processing complete for PR_LRS.IEVS_SAVE_EXCEPT
[2023-06-29T23:23:53.780+0000] {SparkOracle2FileStore.py:80} INFO - processing 6 out of 48
[2023-06-29T23:23:53.780+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WTW_24_MONTH_SIGN_DATE
[2023-06-29T23:23:53.780+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:23:54.872+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WTW_24_MONTH_SIGN_DATE
[2023-06-29T23:23:54.872+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:23:56.202+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:23:56.780+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:23:56.780+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:23:58.481+0000] {SparkOracle2FileStore.py:103} INFO - 830945
[2023-06-29T23:23:58.481+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:23:59.697+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/WTW_24_MONTH_SIGN_DATE exists...
[2023-06-29T23:23:59.697+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:23:59.706+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:23:59.706+0000] {client.py:320} INFO - Fetching status for '/dev/WTW_24_MONTH_SIGN_DATE'.
[2023-06-29T23:23:59.709+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:23:59.709+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:23:59.763+0000] {SparkOracle2FileStore.py:126} INFO - read dir table should not fail and go in here...
[2023-06-29T23:24:41.867+0000] {SparkOracle2FileStore.py:139} INFO - no rows to upsert on table WTW_24_MONTH_SIGN_DATE
[2023-06-29T23:25:05.906+0000] {local_task_job_runner.py:291} WARNING - State of this instance has been externally set to success. Terminating instance.
[2023-06-29T23:25:05.908+0000] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 4617. PIDs of all processes in the group: [4618, 4617]
[2023-06-29T23:25:05.908+0000] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 4617
[2023-06-29T23:25:05.908+0000] {taskinstance.py:1517} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-06-29T23:25:05.908+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1519, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-06-29T23:25:05.933+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:05.933+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1519, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-06-29T23:25:05.934+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:05.934+0000] {SparkOracle2FileStore.py:172} INFO - Error Processing Table PR_LRS.WTW_24_MONTH_SIGN_DATE:An error occurred while calling o441.isEmpty
[2023-06-29T23:25:05.934+0000] {SparkOracle2FileStore.py:80} INFO - processing 6 out of 48
[2023-06-29T23:25:05.934+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.RULES_ADMIN
[2023-06-29T23:25:05.934+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:25:06.414+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[2023-06-29T23:25:06.415+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.415+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-06-29T23:25:06.415+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.415+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: An error occurred while calling o450.load
[2023-06-29T23:25:06.415+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-06-29T23:25:06.415+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.RULES_ADMIN
[2023-06-29T23:25:06.415+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-06-29T23:25:06.415+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.415+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-06-29T23:25:06.415+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.415+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-06-29T23:25:06.415+0000] {SparkOracle2FileStore.py:90} INFO - could not reliablily get upper and lower bounds of table PR_LRS.RULES_ADMIN, reading without partition 
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-06-29T23:25:06.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-06-29T23:25:06.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.416+0000] {SparkOracle2FileStore.py:100} INFO - Filter Processor Disabled
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:25:06.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-06-29T23:25:06.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.416+0000] {SparkOracle2FileStore.py:103} INFO - None
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-06-29T23:25:06.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-06-29T23:25:06.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.416+0000] {logging_mixin.py:149} INFO - Checking if HDFS Directory /dev/RULES_ADMIN exists...
[2023-06-29T23:25:06.416+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T23:25:06.424+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T23:25:06.424+0000] {client.py:320} INFO - Fetching status for '/dev/RULES_ADMIN'.
[2023-06-29T23:25:06.428+0000] {logging_mixin.py:149} INFO - HDFS Path Exists
[2023-06-29T23:25:06.428+0000] {SparkOracle2FileStore.py:113} INFO - Should go in here if table dir exists
[2023-06-29T23:25:06.428+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.428+0000] {logging_mixin.py:149} INFO - Error in reading dataframe:[Errno 111] Connection refused
[2023-06-29T23:25:06.428+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-06-29T23:25:06.428+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-06-29T23:25:06.428+0000] {SparkOracle2FileStore.py:119} INFO - Table write error, skipping table
[2023-06-29T23:25:06.428+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-06-29T23:25:06.435+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=Oracle_to_Filestore, task_id=execute_function_task, execution_date=20230629T231736, start_date=20230629T231737, end_date=20230629T232506
[2023-06-29T23:25:06.462+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=4617, status='terminated', exitcode=0, started='23:17:36') (4617) terminated with exit code 0
[2023-06-29T23:25:06.462+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=4618, status='terminated', started='23:17:37') (4618) terminated with exit code None
