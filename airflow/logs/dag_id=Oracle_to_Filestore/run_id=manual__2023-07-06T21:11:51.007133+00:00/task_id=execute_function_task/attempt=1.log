[2023-07-06T21:11:52.339+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-07-06T21:11:51.007133+00:00 [queued]>
[2023-07-06T21:11:52.343+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-07-06T21:11:51.007133+00:00 [queued]>
[2023-07-06T21:11:52.344+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-07-06T21:11:52.350+0000] {taskinstance.py:1327} INFO - Executing <Task(_PythonDecoratedOperator): execute_function_task> on 2023-07-06 21:11:51.007133+00:00
[2023-07-06T21:11:52.353+0000] {standard_task_runner.py:57} INFO - Started process 342 to run task
[2023-07-06T21:11:52.355+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Oracle_to_Filestore', 'execute_function_task', 'manual__2023-07-06T21:11:51.007133+00:00', '--job-id', '852', '--raw', '--subdir', 'DAGS_FOLDER/Python-Delta-Lake/Dags/SparkOracle2FileStoreDag.py', '--cfg-path', '/tmp/tmp4foly79t']
[2023-07-06T21:11:52.357+0000] {standard_task_runner.py:85} INFO - Job 852: Subtask execute_function_task
[2023-07-06T21:11:52.383+0000] {task_command.py:410} INFO - Running <TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-07-06T21:11:51.007133+00:00 [running]> on host 876817aabcc6
[2023-07-06T21:11:52.426+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='phomsophaN@saccounty.net' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Oracle_to_Filestore' AIRFLOW_CTX_TASK_ID='execute_function_task' AIRFLOW_CTX_EXECUTION_DATE='2023-07-06T21:11:51.007133+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-07-06T21:11:51.007133+00:00'
[2023-07-06T21:11:52.426+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-07-06T21:11:52.427+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-07-06T21:11:52.427+0000] {logging_mixin.py:149} INFO - setting up configured spark connection Cluster
[2023-07-06T21:11:52.427+0000] {logging_mixin.py:149} INFO - Initializing support for delta lake spark context
[2023-07-06T21:11:56.316+0000] {logging_mixin.py:149} INFO - Returning Spark Context
[2023-07-06T21:11:56.317+0000] {logging_mixin.py:149} INFO - Spark Connection check - session found
[2023-07-06T21:11:56.849+0000] {logging_mixin.py:149} INFO - Attempt to read Msql Table by query: select * from DeltaLake.OracleTablesLog
        where OracleRows < 1000000 AND OracleRows > 10000 AND OracleSizeInMB < 2500 AND CountyFilter IS NOT NULL and PrimaryKeyColumn !=''
[2023-07-06T21:12:00.236+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.237+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.238+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.242+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.242+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.243+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.244+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.245+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-06T21:12:00.256+0000] {SparkOracle2FileStore.py:68} INFO - ['PR_LRS.FOSTER_FAM_AGNC', 'PR_LRS.EBT_EXPG_EXCPT', 'PR_LRS.ENCL_ESTIMATE', 'PR_LRS.UNIT', 'PR_LRS.IEVS_SAVE_EXCEPT', 'PR_LRS.RULES_ADMIN', 'PR_LRS.WTW_24_MONTH_SIGN_DATE', 'PR_LRS.COUNTY_PARAMTR_ADMIN_HST', 'PR_LRS.C4Y_PREG', 'PR_LRS.IEVS_PRISON_MATCH', 'PR_LRS.ORG_ACCT', 'PR_LRS.TRAIN_PGM', 'PR_LRS.IFD_SSI', 'PR_LRS.C4Y_PERS_NON_COMPL', 'PR_LRS.POS', 'PR_LRS.ADH_SUMM', 'PR_LRS.WDTIP_PGM_PARTICPTN', 'PR_LRS.HEAR_SUMM', 'PR_LRS.WDTIP_ALERT', 'PR_LRS.IHSS_REFRL', 'PR_LRS.SFIS_COUNTY_INFO', 'PR_LRS.STAFF', 'PR_LRS.MEDS_ALERT_CONFIG', 'PR_LRS.BATCH_JOB', 'PR_LRS.IHSS_CASE', 'PR_LRS.RULES_ADMIN_HST', 'PR_LRS.TAX_INTRCPT', 'PR_LRS.WTW_24_MONTH_SIGN_DATE_HST', 'PR_LRS.COUNTY_PARAMTR_ADMIN', 'PR_LRS.OCAT', 'PR_LRS.WDTIP_EXCEED_CLOCK', 'PR_LRS.AUTO_ACTN', 'PR_LRS.IFD_DUPL_DETL', 'PR_LRS.EBT_FRAUD_ACTIV', 'PR_LRS.GA_GR_TIME_LIMIT', 'PR_LRS.GRP_HOMES', 'PR_LRS.ASSET_VERIF', 'PR_LRS.FUND_CODE_MAP', 'PR_LRS.C4Y_OTHER_PGM_ASSIST', 'PR_LRS.IEVS_FF_MEDS', 'PR_LRS.COLLAB_CONTRACT', 'PR_LRS.WDTIP_APPRCH_CLOCK', 'PR_LRS.EXTRNL_STAFF_COUNTY_STAT', 'PR_LRS.VEND_IDENTIF', 'PR_LRS.OCAT_PERS', 'PR_LRS.MEDS_ALERT_CONFIG_HST', 'PR_LRS.WPR_SAMPLE_CASE', 'PR_LRS.PERS_TIME_TRACK_DETL']
[2023-07-06T21:12:00.257+0000] {SparkOracle2FileStore.py:86} INFO - processing 1 out of 48
[2023-07-06T21:12:00.258+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.FOSTER_FAM_AGNC
[2023-07-06T21:12:00.258+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:01.866+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.FOSTER_FAM_AGNC
[2023-07-06T21:12:01.866+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:03.856+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:12:04.379+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:12:04.379+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:05.531+0000] {SparkOracle2FileStore.py:109} INFO - 34262
[2023-07-06T21:12:05.531+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:06.756+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/FOSTER_FAM_AGNC
[2023-07-06T21:12:06.756+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:12:06.756+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:12:12.609+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o129.save.
: org.apache.spark.sql.delta.DeltaIOException: Cannot create file:/home/nicholas/dev/output/FOSTER_FAM_AGNC/_delta_log
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException(DeltaErrors.scala:1494)
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException$(DeltaErrors.scala:1493)
	at org.apache.spark.sql.delta.DeltaErrors$.cannotCreateLogPathException(DeltaErrors.scala:2681)
	at org.apache.spark.sql.delta.DeltaLog.ensureLogDirectoryExist(DeltaLog.scala:440)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit(OptimisticTransaction.scala:1209)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit$(OptimisticTransaction.scala:1151)
	at org.apache.spark.sql.delta.OptimisticTransaction.prepareCommit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.liftedTree1$1(OptimisticTransaction.scala:907)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.$anonfun$commitImpl$1(OptimisticTransaction.scala:899)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl(OptimisticTransaction.scala:896)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl$(OptimisticTransaction.scala:892)
	at org.apache.spark.sql.delta.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit(OptimisticTransaction.scala:886)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit$(OptimisticTransaction.scala:885)
	at org.apache.spark.sql.delta.OptimisticTransaction.commit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:100)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:233)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:171)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:303)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-06T21:12:12.610+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.FOSTER_FAM_AGNC
[2023-07-06T21:12:12.610+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.FOSTER_FAM_AGNC:local variable 'directory_df' referenced before assignment
[2023-07-06T21:12:12.611+0000] {SparkOracle2FileStore.py:86} INFO - processing 2 out of 48
[2023-07-06T21:12:12.611+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.EBT_EXPG_EXCPT
[2023-07-06T21:12:12.611+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:13.706+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.EBT_EXPG_EXCPT
[2023-07-06T21:12:13.706+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:14.813+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:12:15.387+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:12:15.387+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:16.600+0000] {SparkOracle2FileStore.py:109} INFO - 316506
[2023-07-06T21:12:16.600+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:17.895+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/EBT_EXPG_EXCPT
[2023-07-06T21:12:17.895+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:12:17.895+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:12:39.629+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o183.save.
: org.apache.spark.sql.delta.DeltaIOException: Cannot create file:/home/nicholas/dev/output/EBT_EXPG_EXCPT/_delta_log
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException(DeltaErrors.scala:1494)
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException$(DeltaErrors.scala:1493)
	at org.apache.spark.sql.delta.DeltaErrors$.cannotCreateLogPathException(DeltaErrors.scala:2681)
	at org.apache.spark.sql.delta.DeltaLog.ensureLogDirectoryExist(DeltaLog.scala:440)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit(OptimisticTransaction.scala:1209)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit$(OptimisticTransaction.scala:1151)
	at org.apache.spark.sql.delta.OptimisticTransaction.prepareCommit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.liftedTree1$1(OptimisticTransaction.scala:907)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.$anonfun$commitImpl$1(OptimisticTransaction.scala:899)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl(OptimisticTransaction.scala:896)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl$(OptimisticTransaction.scala:892)
	at org.apache.spark.sql.delta.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit(OptimisticTransaction.scala:886)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit$(OptimisticTransaction.scala:885)
	at org.apache.spark.sql.delta.OptimisticTransaction.commit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:100)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:233)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:171)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:303)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-06T21:12:39.630+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.EBT_EXPG_EXCPT
[2023-07-06T21:12:39.630+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.EBT_EXPG_EXCPT:local variable 'directory_df' referenced before assignment
[2023-07-06T21:12:39.630+0000] {SparkOracle2FileStore.py:86} INFO - processing 3 out of 48
[2023-07-06T21:12:39.631+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.ENCL_ESTIMATE
[2023-07-06T21:12:39.631+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:40.780+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.ENCL_ESTIMATE
[2023-07-06T21:12:40.780+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:41.867+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:12:42.427+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:12:42.427+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:43.548+0000] {SparkOracle2FileStore.py:109} INFO - 25979
[2023-07-06T21:12:43.548+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:44.732+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/ENCL_ESTIMATE
[2023-07-06T21:12:44.732+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:12:44.732+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:12:46.344+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o237.save.
: org.apache.spark.sql.delta.DeltaIOException: Cannot create file:/home/nicholas/dev/output/ENCL_ESTIMATE/_delta_log
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException(DeltaErrors.scala:1494)
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException$(DeltaErrors.scala:1493)
	at org.apache.spark.sql.delta.DeltaErrors$.cannotCreateLogPathException(DeltaErrors.scala:2681)
	at org.apache.spark.sql.delta.DeltaLog.ensureLogDirectoryExist(DeltaLog.scala:440)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit(OptimisticTransaction.scala:1209)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit$(OptimisticTransaction.scala:1151)
	at org.apache.spark.sql.delta.OptimisticTransaction.prepareCommit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.liftedTree1$1(OptimisticTransaction.scala:907)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.$anonfun$commitImpl$1(OptimisticTransaction.scala:899)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl(OptimisticTransaction.scala:896)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl$(OptimisticTransaction.scala:892)
	at org.apache.spark.sql.delta.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit(OptimisticTransaction.scala:886)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit$(OptimisticTransaction.scala:885)
	at org.apache.spark.sql.delta.OptimisticTransaction.commit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:100)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:233)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:171)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:303)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-06T21:12:46.344+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.ENCL_ESTIMATE
[2023-07-06T21:12:46.344+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.ENCL_ESTIMATE:local variable 'directory_df' referenced before assignment
[2023-07-06T21:12:46.345+0000] {SparkOracle2FileStore.py:86} INFO - processing 4 out of 48
[2023-07-06T21:12:46.345+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.UNIT
[2023-07-06T21:12:46.345+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:47.494+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.UNIT
[2023-07-06T21:12:47.494+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:48.589+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:12:49.157+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:12:49.157+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:50.314+0000] {SparkOracle2FileStore.py:109} INFO - 42879
[2023-07-06T21:12:50.314+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:51.405+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/UNIT
[2023-07-06T21:12:51.405+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:12:51.405+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:12:53.951+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o291.save.
: org.apache.spark.sql.delta.DeltaIOException: Cannot create file:/home/nicholas/dev/output/UNIT/_delta_log
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException(DeltaErrors.scala:1494)
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException$(DeltaErrors.scala:1493)
	at org.apache.spark.sql.delta.DeltaErrors$.cannotCreateLogPathException(DeltaErrors.scala:2681)
	at org.apache.spark.sql.delta.DeltaLog.ensureLogDirectoryExist(DeltaLog.scala:440)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit(OptimisticTransaction.scala:1209)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit$(OptimisticTransaction.scala:1151)
	at org.apache.spark.sql.delta.OptimisticTransaction.prepareCommit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.liftedTree1$1(OptimisticTransaction.scala:907)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.$anonfun$commitImpl$1(OptimisticTransaction.scala:899)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl(OptimisticTransaction.scala:896)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl$(OptimisticTransaction.scala:892)
	at org.apache.spark.sql.delta.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit(OptimisticTransaction.scala:886)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit$(OptimisticTransaction.scala:885)
	at org.apache.spark.sql.delta.OptimisticTransaction.commit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:100)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:233)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:171)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:303)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-06T21:12:53.952+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.UNIT
[2023-07-06T21:12:53.952+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.UNIT:local variable 'directory_df' referenced before assignment
[2023-07-06T21:12:53.952+0000] {SparkOracle2FileStore.py:86} INFO - processing 5 out of 48
[2023-07-06T21:12:53.952+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IEVS_SAVE_EXCEPT
[2023-07-06T21:12:53.952+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:55.065+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IEVS_SAVE_EXCEPT
[2023-07-06T21:12:55.065+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:12:56.286+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:12:56.817+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:12:56.817+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:58.132+0000] {SparkOracle2FileStore.py:109} INFO - 397776
[2023-07-06T21:12:58.132+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:12:59.450+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IEVS_SAVE_EXCEPT
[2023-07-06T21:12:59.450+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:12:59.450+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:13:31.511+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o345.save.
: org.apache.spark.sql.delta.DeltaIOException: Cannot create file:/home/nicholas/dev/output/IEVS_SAVE_EXCEPT/_delta_log
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException(DeltaErrors.scala:1494)
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException$(DeltaErrors.scala:1493)
	at org.apache.spark.sql.delta.DeltaErrors$.cannotCreateLogPathException(DeltaErrors.scala:2681)
	at org.apache.spark.sql.delta.DeltaLog.ensureLogDirectoryExist(DeltaLog.scala:440)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit(OptimisticTransaction.scala:1209)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit$(OptimisticTransaction.scala:1151)
	at org.apache.spark.sql.delta.OptimisticTransaction.prepareCommit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.liftedTree1$1(OptimisticTransaction.scala:907)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.$anonfun$commitImpl$1(OptimisticTransaction.scala:899)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl(OptimisticTransaction.scala:896)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl$(OptimisticTransaction.scala:892)
	at org.apache.spark.sql.delta.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit(OptimisticTransaction.scala:886)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit$(OptimisticTransaction.scala:885)
	at org.apache.spark.sql.delta.OptimisticTransaction.commit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:100)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:233)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:171)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:303)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-06T21:13:31.511+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.IEVS_SAVE_EXCEPT
[2023-07-06T21:13:31.512+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IEVS_SAVE_EXCEPT:local variable 'directory_df' referenced before assignment
[2023-07-06T21:13:31.512+0000] {SparkOracle2FileStore.py:86} INFO - processing 6 out of 48
[2023-07-06T21:13:31.512+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.RULES_ADMIN
[2023-07-06T21:13:31.512+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:13:32.566+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.RULES_ADMIN
[2023-07-06T21:13:32.567+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:13:33.785+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:13:34.368+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:13:34.368+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:13:35.636+0000] {SparkOracle2FileStore.py:109} INFO - 25885
[2023-07-06T21:13:35.636+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:13:36.747+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/RULES_ADMIN
[2023-07-06T21:13:36.747+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:13:36.747+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:13:38.305+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o399.save.
: org.apache.spark.sql.delta.DeltaIOException: Cannot create file:/home/nicholas/dev/output/RULES_ADMIN/_delta_log
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException(DeltaErrors.scala:1494)
	at org.apache.spark.sql.delta.DeltaErrorsBase.cannotCreateLogPathException$(DeltaErrors.scala:1493)
	at org.apache.spark.sql.delta.DeltaErrors$.cannotCreateLogPathException(DeltaErrors.scala:2681)
	at org.apache.spark.sql.delta.DeltaLog.ensureLogDirectoryExist(DeltaLog.scala:440)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit(OptimisticTransaction.scala:1209)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.prepareCommit$(OptimisticTransaction.scala:1151)
	at org.apache.spark.sql.delta.OptimisticTransaction.prepareCommit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.liftedTree1$1(OptimisticTransaction.scala:907)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.$anonfun$commitImpl$1(OptimisticTransaction.scala:899)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:140)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:138)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:133)
	at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)
	at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:132)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:122)
	at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:112)
	at org.apache.spark.sql.delta.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl(OptimisticTransaction.scala:896)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commitImpl$(OptimisticTransaction.scala:892)
	at org.apache.spark.sql.delta.OptimisticTransaction.commitImpl(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit(OptimisticTransaction.scala:886)
	at org.apache.spark.sql.delta.OptimisticTransactionImpl.commit$(OptimisticTransaction.scala:885)
	at org.apache.spark.sql.delta.OptimisticTransaction.commit(OptimisticTransaction.scala:129)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:100)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:233)
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:92)
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:171)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:303)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-06T21:13:38.305+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.RULES_ADMIN
[2023-07-06T21:13:38.305+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.RULES_ADMIN:local variable 'directory_df' referenced before assignment
[2023-07-06T21:13:38.305+0000] {SparkOracle2FileStore.py:86} INFO - processing 7 out of 48
[2023-07-06T21:13:38.305+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WTW_24_MONTH_SIGN_DATE
[2023-07-06T21:13:38.305+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:13:39.487+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WTW_24_MONTH_SIGN_DATE
[2023-07-06T21:13:39.487+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:13:40.556+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:13:41.139+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:13:41.139+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:13:42.841+0000] {SparkOracle2FileStore.py:109} INFO - 830945
[2023-07-06T21:13:42.841+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:13:44.158+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WTW_24_MONTH_SIGN_DATE
[2023-07-06T21:13:44.158+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:13:44.158+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.353+0000] {local_task_job_runner.py:291} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2023-07-06T21:14:08.354+0000] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 342. PIDs of all processes in the group: [343, 342]
[2023-07-06T21:14:08.354+0000] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 342
[2023-07-06T21:14:08.354+0000] {taskinstance.py:1517} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-07-06T21:14:08.355+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1519, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-07-06T21:14:08.355+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.356+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1519, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-07-06T21:14:08.357+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.357+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:An error occurred while calling o453.save
[2023-07-06T21:14:08.358+0000] {SparkOracle2FileStore.py:175} INFO - Table Processing complete for PR_LRS.WTW_24_MONTH_SIGN_DATE
[2023-07-06T21:14:08.359+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WTW_24_MONTH_SIGN_DATE:local variable 'directory_df' referenced before assignment
[2023-07-06T21:14:08.359+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.359+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column HST_ID on table PR_LRS.COUNTY_PARAMTR_ADMIN_HST
[2023-07-06T21:14:08.359+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.822+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[2023-07-06T21:14:08.823+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.823+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2023-07-06T21:14:08.823+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: An error occurred while calling o461.load
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column HST_ID on table PR_LRS.COUNTY_PARAMTR_ADMIN_HST
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.823+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.823+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.823+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.COUNTY_PARAMTR_ADMIN_HST, reading without partition 
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.823+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.823+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.823+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.823+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/COUNTY_PARAMTR_ADMIN_HST
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.824+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.824+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.COUNTY_PARAMTR_ADMIN_HST:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.824+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.C4Y_PREG
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.C4Y_PREG
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.824+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.824+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.825+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.C4Y_PREG, reading without partition 
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/C4Y_PREG
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.825+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.825+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.C4Y_PREG:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.825+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IEVS_PRISON_MATCH
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.825+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.825+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IEVS_PRISON_MATCH
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.826+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.IEVS_PRISON_MATCH, reading without partition 
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.826+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IEVS_PRISON_MATCH
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.826+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.826+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.826+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IEVS_PRISON_MATCH:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.827+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.ORG_ACCT
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.ORG_ACCT
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.827+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.ORG_ACCT, reading without partition 
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.827+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.827+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/ORG_ACCT
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.828+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.828+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.ORG_ACCT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.828+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.TRAIN_PGM
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.TRAIN_PGM
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.828+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.TRAIN_PGM, reading without partition 
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.828+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.828+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.828+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/TRAIN_PGM
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.829+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.829+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.TRAIN_PGM:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.829+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IFD_SSI
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IFD_SSI
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.829+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.IFD_SSI, reading without partition 
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.829+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.829+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IFD_SSI
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.830+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.830+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IFD_SSI:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.830+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.C4Y_PERS_NON_COMPL
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.C4Y_PERS_NON_COMPL
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.830+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.830+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.831+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.C4Y_PERS_NON_COMPL, reading without partition 
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/C4Y_PERS_NON_COMPL
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.831+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.831+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.C4Y_PERS_NON_COMPL:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.831+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.POS
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.831+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.831+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.POS
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.832+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.POS, reading without partition 
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.832+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/POS
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.832+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.832+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.POS:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.832+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.ADH_SUMM
[2023-07-06T21:14:08.832+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.ADH_SUMM
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.833+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.ADH_SUMM, reading without partition 
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.833+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/ADH_SUMM
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.833+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.833+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.834+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.ADH_SUMM:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.834+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WDTIP_PGM_PARTICPTN
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WDTIP_PGM_PARTICPTN
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.834+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.WDTIP_PGM_PARTICPTN, reading without partition 
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.834+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.834+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.834+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WDTIP_PGM_PARTICPTN
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.835+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.835+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WDTIP_PGM_PARTICPTN:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.835+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.HEAR_SUMM
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.HEAR_SUMM
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.835+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.HEAR_SUMM, reading without partition 
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.835+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.835+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.835+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/HEAR_SUMM
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.836+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.836+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.HEAR_SUMM:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.836+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WDTIP_ALERT
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WDTIP_ALERT
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.836+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.836+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.837+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.WDTIP_ALERT, reading without partition 
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.837+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.837+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.837+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.837+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.837+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.837+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.837+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.837+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WDTIP_ALERT
[2023-07-06T21:14:08.837+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.838+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.838+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WDTIP_ALERT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.838+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IHSS_REFRL
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.838+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.838+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IHSS_REFRL
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.838+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.838+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.838+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.IHSS_REFRL, reading without partition 
[2023-07-06T21:14:08.838+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.838+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IHSS_REFRL
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.839+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.839+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IHSS_REFRL:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.839+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.SFIS_COUNTY_INFO
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.839+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.839+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.SFIS_COUNTY_INFO
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.840+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.SFIS_COUNTY_INFO, reading without partition 
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.840+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/SFIS_COUNTY_INFO
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.840+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.840+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.840+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.SFIS_COUNTY_INFO:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.840+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.STAFF
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.STAFF
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.841+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.STAFF, reading without partition 
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.841+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.841+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/STAFF
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.842+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.842+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.STAFF:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.842+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.MEDS_ALERT_CONFIG
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.MEDS_ALERT_CONFIG
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.842+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.MEDS_ALERT_CONFIG, reading without partition 
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.842+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.842+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.842+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/MEDS_ALERT_CONFIG
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.843+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.843+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.MEDS_ALERT_CONFIG:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.843+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.BATCH_JOB
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.BATCH_JOB
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.843+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.843+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.BATCH_JOB, reading without partition 
[2023-07-06T21:14:08.843+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/BATCH_JOB
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.844+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.844+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.BATCH_JOB:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.844+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IHSS_CASE
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.844+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.844+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IHSS_CASE
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.845+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.IHSS_CASE, reading without partition 
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.845+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.845+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IHSS_CASE
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.846+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.846+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IHSS_CASE:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.846+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column HST_ID on table PR_LRS.RULES_ADMIN_HST
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column HST_ID on table PR_LRS.RULES_ADMIN_HST
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.846+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.RULES_ADMIN_HST, reading without partition 
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.846+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.846+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.846+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/RULES_ADMIN_HST
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.847+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.847+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.RULES_ADMIN_HST:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.847+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.TAX_INTRCPT
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.TAX_INTRCPT
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.847+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.847+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.847+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.TAX_INTRCPT, reading without partition 
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/TAX_INTRCPT
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.848+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.848+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.TAX_INTRCPT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.848+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column HST_ID on table PR_LRS.WTW_24_MONTH_SIGN_DATE_HST
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.848+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column HST_ID on table PR_LRS.WTW_24_MONTH_SIGN_DATE_HST
[2023-07-06T21:14:08.848+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.849+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.WTW_24_MONTH_SIGN_DATE_HST, reading without partition 
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.849+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WTW_24_MONTH_SIGN_DATE_HST
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.849+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.849+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WTW_24_MONTH_SIGN_DATE_HST:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.849+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.849+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.COUNTY_PARAMTR_ADMIN
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.COUNTY_PARAMTR_ADMIN
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.850+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.COUNTY_PARAMTR_ADMIN, reading without partition 
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.850+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.850+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/COUNTY_PARAMTR_ADMIN
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.851+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.851+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.COUNTY_PARAMTR_ADMIN:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.851+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.OCAT
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.OCAT
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.851+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.OCAT, reading without partition 
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.851+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.851+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.852+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.852+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/OCAT
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.852+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.852+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.OCAT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.852+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WDTIP_EXCEED_CLOCK
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.852+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.852+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WDTIP_EXCEED_CLOCK
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.852+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.852+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.852+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.WDTIP_EXCEED_CLOCK, reading without partition 
[2023-07-06T21:14:08.852+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WDTIP_EXCEED_CLOCK
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.853+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.853+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WDTIP_EXCEED_CLOCK:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.853+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.AUTO_ACTN
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.853+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.853+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.AUTO_ACTN
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.854+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.AUTO_ACTN, reading without partition 
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.854+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/AUTO_ACTN
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.854+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.854+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.854+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.AUTO_ACTN:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.854+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IFD_DUPL_DETL
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IFD_DUPL_DETL
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.855+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.IFD_DUPL_DETL, reading without partition 
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.855+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.855+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IFD_DUPL_DETL
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.856+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.856+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IFD_DUPL_DETL:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.856+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.EBT_FRAUD_ACTIV
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.856+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.856+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.EBT_FRAUD_ACTIV
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.856+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.856+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.856+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.EBT_FRAUD_ACTIV, reading without partition 
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.856+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.856+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.856+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.856+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/EBT_FRAUD_ACTIV
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.857+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.857+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.EBT_FRAUD_ACTIV:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.857+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.GA_GR_TIME_LIMIT
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.GA_GR_TIME_LIMIT
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.857+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.857+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.GA_GR_TIME_LIMIT, reading without partition 
[2023-07-06T21:14:08.857+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/GA_GR_TIME_LIMIT
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.858+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.858+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.GA_GR_TIME_LIMIT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.858+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.GRP_HOMES
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.GRP_HOMES
[2023-07-06T21:14:08.858+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.858+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.859+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.GRP_HOMES, reading without partition 
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/GRP_HOMES
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.859+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.859+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.GRP_HOMES:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.859+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.ASSET_VERIF
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.859+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.859+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.ASSET_VERIF
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.860+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.ASSET_VERIF, reading without partition 
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.860+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/ASSET_VERIF
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.860+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.860+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.860+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.ASSET_VERIF:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.860+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.FUND_CODE_MAP
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.FUND_CODE_MAP
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.861+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.FUND_CODE_MAP, reading without partition 
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.861+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.861+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/FUND_CODE_MAP
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.862+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.862+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.FUND_CODE_MAP:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.862+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.C4Y_OTHER_PGM_ASSIST
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.C4Y_OTHER_PGM_ASSIST
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.862+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.C4Y_OTHER_PGM_ASSIST, reading without partition 
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.862+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.862+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.862+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/C4Y_OTHER_PGM_ASSIST
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.863+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.863+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.C4Y_OTHER_PGM_ASSIST:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.863+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IEVS_FF_MEDS
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IEVS_FF_MEDS
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.863+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.IEVS_FF_MEDS, reading without partition 
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.863+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.863+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IEVS_FF_MEDS
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.864+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.864+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.IEVS_FF_MEDS:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.864+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.COLLAB_CONTRACT
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.COLLAB_CONTRACT
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.864+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.864+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.865+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.COLLAB_CONTRACT, reading without partition 
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/COLLAB_CONTRACT
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.865+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.865+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.COLLAB_CONTRACT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.865+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WDTIP_APPRCH_CLOCK
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.865+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.865+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WDTIP_APPRCH_CLOCK
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.866+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.WDTIP_APPRCH_CLOCK, reading without partition 
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.866+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WDTIP_APPRCH_CLOCK
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.866+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.866+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.866+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WDTIP_APPRCH_CLOCK:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.867+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.EXTRNL_STAFF_COUNTY_STAT
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.EXTRNL_STAFF_COUNTY_STAT
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.867+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.EXTRNL_STAFF_COUNTY_STAT, reading without partition 
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.867+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.867+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/EXTRNL_STAFF_COUNTY_STAT
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.868+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.868+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.EXTRNL_STAFF_COUNTY_STAT:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.868+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.VEND_IDENTIF
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.VEND_IDENTIF
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.868+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.VEND_IDENTIF, reading without partition 
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.868+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.868+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.869+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.869+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.869+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.869+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.869+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/VEND_IDENTIF
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.869+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.869+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.VEND_IDENTIF:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.869+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.OCAT_PERS
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.869+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.869+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.OCAT_PERS
[2023-07-06T21:14:08.869+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.870+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.OCAT_PERS, reading without partition 
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.870+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/OCAT_PERS
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.870+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.870+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.OCAT_PERS:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.870+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.870+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column HST_ID on table PR_LRS.MEDS_ALERT_CONFIG_HST
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column HST_ID on table PR_LRS.MEDS_ALERT_CONFIG_HST
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.871+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.MEDS_ALERT_CONFIG_HST, reading without partition 
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.871+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.871+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/MEDS_ALERT_CONFIG_HST
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.872+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.872+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.MEDS_ALERT_CONFIG_HST:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.872+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WPR_SAMPLE_CASE
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WPR_SAMPLE_CASE
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.872+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.WPR_SAMPLE_CASE, reading without partition 
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.872+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.872+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.873+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WPR_SAMPLE_CASE
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.873+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.873+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.WPR_SAMPLE_CASE:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.873+0000] {SparkOracle2FileStore.py:86} INFO - processing 8 out of 48
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.PERS_TIME_TRACK_DETL
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Could not get min count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.PERS_TIME_TRACK_DETL
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.873+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by query: [Errno 111] Connection refused
[2023-07-06T21:14:08.873+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Could not get max count: 'NoneType' object has no attribute 'head'
[2023-07-06T21:14:08.874+0000] {SparkOracle2FileStore.py:96} INFO - could not reliablily get upper and lower bounds of table PR_LRS.PERS_TIME_TRACK_DETL, reading without partition 
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-06T21:14:08.874+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Read on oracle table failed: [Errno 111] Connection refused
[2023-07-06T21:14:08.874+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {SparkOracle2FileStore.py:106} INFO - Filter Processor Disabled
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.874+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.874+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {SparkOracle2FileStore.py:109} INFO - None
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-06T21:14:08.874+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Error in reading oracle table by rowcount: [Errno 111] Connection refused
[2023-07-06T21:14:08.874+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/PERS_TIME_TRACK_DETL
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-06T21:14:08.874+0000] {SparkOracle2FileStore.py:170} INFO - Should not go in here if table dir exists
[2023-07-06T21:14:08.874+0000] {logging_mixin.py:149} INFO - Error in writing dataframe:'NoneType' object has no attribute 'write'
[2023-07-06T21:14:08.874+0000] {SparkOracle2FileStore.py:189} INFO - Error Processing Table PR_LRS.PERS_TIME_TRACK_DETL:'NoneType' object has no attribute 'unpersist'
[2023-07-06T21:14:08.874+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-07-06T21:14:08.880+0000] {taskinstance.py:1345} INFO - Marking task as SUCCESS. dag_id=Oracle_to_Filestore, task_id=execute_function_task, execution_date=20230706T211151, start_date=20230706T211152, end_date=20230706T211408
[2023-07-06T21:14:08.894+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=342, status='terminated', exitcode=0, started='21:11:52') (342) terminated with exit code 0
[2023-07-06T21:14:08.895+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=343, status='terminated', started='21:11:52') (343) terminated with exit code None
