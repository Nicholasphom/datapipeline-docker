[2023-06-29T22:33:15.636+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-06-29T22:33:14.607854+00:00 [queued]>
[2023-06-29T22:33:15.641+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-06-29T22:33:14.607854+00:00 [queued]>
[2023-06-29T22:33:15.641+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-29T22:33:15.648+0000] {taskinstance.py:1327} INFO - Executing <Task(_PythonDecoratedOperator): execute_function_task> on 2023-06-29 22:33:14.607854+00:00
[2023-06-29T22:33:15.652+0000] {standard_task_runner.py:57} INFO - Started process 54 to run task
[2023-06-29T22:33:15.654+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Oracle_to_Filestore', 'execute_function_task', 'manual__2023-06-29T22:33:14.607854+00:00', '--job-id', '594', '--raw', '--subdir', 'DAGS_FOLDER/Python-Delta-Lake/Dags/SparkOracle2FileStoreDag.py', '--cfg-path', '/tmp/tmpurba5upc']
[2023-06-29T22:33:15.655+0000] {standard_task_runner.py:85} INFO - Job 594: Subtask execute_function_task
[2023-06-29T22:33:15.681+0000] {task_command.py:410} INFO - Running <TaskInstance: Oracle_to_Filestore.execute_function_task manual__2023-06-29T22:33:14.607854+00:00 [running]> on host a35364001907
[2023-06-29T22:33:15.725+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='phomsophaN@saccounty.net' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Oracle_to_Filestore' AIRFLOW_CTX_TASK_ID='execute_function_task' AIRFLOW_CTX_EXECUTION_DATE='2023-06-29T22:33:14.607854+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-29T22:33:14.607854+00:00'
[2023-06-29T22:33:15.726+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-06-29T22:33:15.726+0000] {logging_mixin.py:149} INFO - setting up configured spark connection Cluster
[2023-06-29T22:33:15.726+0000] {logging_mixin.py:149} INFO - Initializing support for delta lake spark context
[2023-06-29T22:33:18.527+0000] {logging_mixin.py:149} INFO - Returning Spark Context
[2023-06-29T22:33:18.528+0000] {client.py:192} INFO - Instantiated <InsecureClient(url='http://namenode:50070')>.
[2023-06-29T22:33:18.529+0000] {client.py:1123} INFO - Listing '/'.
[2023-06-29T22:33:18.540+0000] {logging_mixin.py:149} INFO - HDFS Connection Successfull
[2023-06-29T22:33:18.541+0000] {logging_mixin.py:149} INFO - HDFS Detected and Connected
[2023-06-29T22:33:18.541+0000] {logging_mixin.py:149} INFO - Spark Connection check - session found
[2023-06-29T22:33:19.107+0000] {logging_mixin.py:149} INFO - Attempt to read Msql Table by query: select * from DeltaLake.OracleTablesLog
        where OracleRows < 1000000 AND OracleRows > 10000 AND OracleSizeInMB < 2500 AND CountyFilter IS NOT NULL and PrimaryKeyColumn !=''
[2023-06-29T22:33:22.510+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.510+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.516+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.517+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.517+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.519+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.520+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-06-29T22:33:22.530+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/Python-Delta-Lake/SparkModules/SparkPipelines/SparkOracle2FileStore.py", line 62, in execute_pipeline
    task_logger.log(self.table_list)
TypeError: Logger.log() missing 1 required positional argument: 'msg'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/decorators/base.py", line 220, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/Python-Delta-Lake/Dags/SparkOracle2FileStoreDag.py", line 47, in execute_function_task
    task.execute_pipeline()
  File "/opt/airflow/dags/Python-Delta-Lake/SparkModules/SparkPipelines/SparkOracle2FileStore.py", line 177, in execute_pipeline
    task_logger.log(f"Error Running Pipeline:{e}")
TypeError: Logger.log() missing 1 required positional argument: 'msg'
[2023-06-29T22:33:22.535+0000] {taskinstance.py:1345} INFO - Marking task as FAILED. dag_id=Oracle_to_Filestore, task_id=execute_function_task, execution_date=20230629T223314, start_date=20230629T223315, end_date=20230629T223322
[2023-06-29T22:33:22.544+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 594 for task execute_function_task (Logger.log() missing 1 required positional argument: 'msg'; 54)
[2023-06-29T22:33:22.554+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-06-29T22:33:22.562+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
