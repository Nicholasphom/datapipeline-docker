[2023-07-12T00:18:39.832+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Oracle_to_Filestore_Concurrent.execute_task2 manual__2023-07-12T00:18:38.617307+00:00 [queued]>
[2023-07-12T00:18:39.836+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Oracle_to_Filestore_Concurrent.execute_task2 manual__2023-07-12T00:18:38.617307+00:00 [queued]>
[2023-07-12T00:18:39.837+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-07-12T00:18:39.843+0000] {taskinstance.py:1327} INFO - Executing <Task(_PythonDecoratedOperator): execute_task2> on 2023-07-12 00:18:38.617307+00:00
[2023-07-12T00:18:39.847+0000] {standard_task_runner.py:57} INFO - Started process 67 to run task
[2023-07-12T00:18:39.849+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Oracle_to_Filestore_Concurrent', 'execute_task2', 'manual__2023-07-12T00:18:38.617307+00:00', '--job-id', '1097', '--raw', '--subdir', 'DAGS_FOLDER/Python-Delta-Lake/Dags/SparkOracle2FileStoreDag.py', '--cfg-path', '/tmp/tmpygvozrm4']
[2023-07-12T00:18:39.851+0000] {standard_task_runner.py:85} INFO - Job 1097: Subtask execute_task2
[2023-07-12T00:18:39.875+0000] {task_command.py:410} INFO - Running <TaskInstance: Oracle_to_Filestore_Concurrent.execute_task2 manual__2023-07-12T00:18:38.617307+00:00 [running]> on host 876817aabcc6
[2023-07-12T00:18:39.920+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='phomsophaN@saccounty.net' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Oracle_to_Filestore_Concurrent' AIRFLOW_CTX_TASK_ID='execute_task2' AIRFLOW_CTX_EXECUTION_DATE='2023-07-12T00:18:38.617307+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-07-12T00:18:38.617307+00:00'
[2023-07-12T00:18:39.920+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-07-12T00:18:39.920+0000] {logging_mixin.py:149} INFO - setting up configured spark connection Cluster
[2023-07-12T00:18:39.921+0000] {logging_mixin.py:149} INFO - Initializing support for delta lake spark context
[2023-07-12T00:18:42.212+0000] {logging_mixin.py:149} INFO - Returning Spark Context
[2023-07-12T00:18:42.213+0000] {logging_mixin.py:149} INFO - Spark Connection check - session found
[2023-07-12T00:18:42.689+0000] {logging_mixin.py:149} INFO - Attempt to read Msql Table by query: select * from DeltaLake.OracleTablesLog
        where OracleRows < 10000000 AND OracleRows > 0 AND CountyFilter IS NOT NULL and PrimaryKeyColumn !=''
[2023-07-12T00:18:46.189+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.190+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.191+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.196+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.196+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.197+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.198+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.199+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-12T00:18:46.211+0000] {SparkOracle2FileStore.py:83} INFO - Skipping log tables and reading tables directly
[2023-07-12T00:18:46.212+0000] {SparkOracle2FileStore.py:93} INFO - processing 1 out of 60
[2023-07-12T00:18:46.212+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.FLAG_TRACK
[2023-07-12T00:18:46.212+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:18:47.815+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.FLAG_TRACK
[2023-07-12T00:18:47.816+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:18:48.973+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-12T00:18:49.537+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-12T00:18:49.537+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:18:50.676+0000] {SparkOracle2FileStore.py:116} INFO - 6656
[2023-07-12T00:18:50.676+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:18:52.687+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/FLAG_TRACK
[2023-07-12T00:18:52.687+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-12T00:18:52.687+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-12T00:18:52.687+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
[2023-07-12T00:19:00.320+0000] {SparkOracle2FileStore.py:184} INFO - Table Processing complete for PR_LRS.FLAG_TRACK
[2023-07-12T00:19:00.412+0000] {SparkOracle2FileStore.py:93} INFO - processing 2 out of 60
[2023-07-12T00:19:00.412+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.OCAT
[2023-07-12T00:19:00.412+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:01.533+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.OCAT
[2023-07-12T00:19:01.533+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:02.676+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-12T00:19:03.204+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-12T00:19:03.204+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:04.460+0000] {SparkOracle2FileStore.py:116} INFO - 176399
[2023-07-12T00:19:04.460+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:05.695+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/OCAT
[2023-07-12T00:19:05.695+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-12T00:19:05.695+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-12T00:19:05.695+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
[2023-07-12T00:19:26.503+0000] {SparkOracle2FileStore.py:184} INFO - Table Processing complete for PR_LRS.OCAT
[2023-07-12T00:19:26.575+0000] {SparkOracle2FileStore.py:93} INFO - processing 3 out of 60
[2023-07-12T00:19:26.575+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.OFFICE
[2023-07-12T00:19:26.576+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:27.734+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.OFFICE
[2023-07-12T00:19:27.734+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:28.834+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-12T00:19:29.376+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-12T00:19:29.376+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:30.447+0000] {SparkOracle2FileStore.py:116} INFO - 2149
[2023-07-12T00:19:30.448+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:31.583+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/OFFICE
[2023-07-12T00:19:31.583+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-12T00:19:31.583+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-12T00:19:31.584+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
[2023-07-12T00:19:33.814+0000] {SparkOracle2FileStore.py:184} INFO - Table Processing complete for PR_LRS.OFFICE
[2023-07-12T00:19:33.881+0000] {SparkOracle2FileStore.py:93} INFO - processing 4 out of 60
[2023-07-12T00:19:33.881+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.WDTIP_EXCEED_CLOCK
[2023-07-12T00:19:33.881+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:35.045+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.WDTIP_EXCEED_CLOCK
[2023-07-12T00:19:35.045+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:37.035+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-12T00:19:37.600+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-12T00:19:37.600+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:38.801+0000] {SparkOracle2FileStore.py:116} INFO - 17802
[2023-07-12T00:19:38.802+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:39.914+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/WDTIP_EXCEED_CLOCK
[2023-07-12T00:19:39.914+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-12T00:19:39.914+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-12T00:19:39.914+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
[2023-07-12T00:19:42.463+0000] {SparkOracle2FileStore.py:184} INFO - Table Processing complete for PR_LRS.WDTIP_EXCEED_CLOCK
[2023-07-12T00:19:42.532+0000] {SparkOracle2FileStore.py:93} INFO - processing 5 out of 60
[2023-07-12T00:19:42.532+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.AUTO_ACTN
[2023-07-12T00:19:42.532+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:43.616+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.AUTO_ACTN
[2023-07-12T00:19:43.616+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:44.763+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-12T00:19:45.331+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-12T00:19:45.332+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:46.469+0000] {SparkOracle2FileStore.py:116} INFO - 13113
[2023-07-12T00:19:46.469+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:47.653+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/AUTO_ACTN
[2023-07-12T00:19:47.653+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-12T00:19:47.653+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-12T00:19:47.653+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
[2023-07-12T00:19:49.820+0000] {SparkOracle2FileStore.py:184} INFO - Table Processing complete for PR_LRS.AUTO_ACTN
[2023-07-12T00:19:49.889+0000] {SparkOracle2FileStore.py:93} INFO - processing 6 out of 60
[2023-07-12T00:19:49.889+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.IFD_DUPL_DETL
[2023-07-12T00:19:49.890+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:51.022+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.IFD_DUPL_DETL
[2023-07-12T00:19:51.022+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-12T00:19:52.105+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-12T00:19:52.718+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-12T00:19:52.718+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:55.560+0000] {SparkOracle2FileStore.py:116} INFO - 353610
[2023-07-12T00:19:55.560+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-12T00:19:56.820+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/IFD_DUPL_DETL
[2023-07-12T00:19:56.821+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-12T00:19:56.821+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-12T00:19:56.821+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
