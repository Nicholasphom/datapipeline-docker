[2023-07-11T23:03:54.716+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Oracle_to_Filestore_Concurrent.execute_task2 manual__2023-07-11T23:03:53.232443+00:00 [queued]>
[2023-07-11T23:03:54.721+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Oracle_to_Filestore_Concurrent.execute_task2 manual__2023-07-11T23:03:53.232443+00:00 [queued]>
[2023-07-11T23:03:54.721+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-07-11T23:03:54.729+0000] {taskinstance.py:1327} INFO - Executing <Task(_PythonDecoratedOperator): execute_task2> on 2023-07-11 23:03:53.232443+00:00
[2023-07-11T23:03:54.732+0000] {standard_task_runner.py:57} INFO - Started process 75 to run task
[2023-07-11T23:03:54.734+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Oracle_to_Filestore_Concurrent', 'execute_task2', 'manual__2023-07-11T23:03:53.232443+00:00', '--job-id', '1047', '--raw', '--subdir', 'DAGS_FOLDER/Python-Delta-Lake/Dags/SparkOracle2FileStoreDag.py', '--cfg-path', '/tmp/tmpk6hudrxb']
[2023-07-11T23:03:54.735+0000] {standard_task_runner.py:85} INFO - Job 1047: Subtask execute_task2
[2023-07-11T23:03:54.764+0000] {task_command.py:410} INFO - Running <TaskInstance: Oracle_to_Filestore_Concurrent.execute_task2 manual__2023-07-11T23:03:53.232443+00:00 [running]> on host 876817aabcc6
[2023-07-11T23:03:54.808+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='phomsophaN@saccounty.net' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Oracle_to_Filestore_Concurrent' AIRFLOW_CTX_TASK_ID='execute_task2' AIRFLOW_CTX_EXECUTION_DATE='2023-07-11T23:03:53.232443+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-07-11T23:03:53.232443+00:00'
[2023-07-11T23:03:54.809+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-07-11T23:03:54.809+0000] {logging_mixin.py:149} INFO - SparkSession Not found, creating one
[2023-07-11T23:03:54.809+0000] {logging_mixin.py:149} INFO - setting up configured spark connection Cluster
[2023-07-11T23:03:54.809+0000] {logging_mixin.py:149} INFO - Initializing support for delta lake spark context
[2023-07-11T23:03:57.611+0000] {logging_mixin.py:149} INFO - Returning Spark Context
[2023-07-11T23:03:57.612+0000] {logging_mixin.py:149} INFO - Spark Connection check - session found
[2023-07-11T23:03:58.352+0000] {logging_mixin.py:149} INFO - Attempt to read Msql Table by query: select * from DeltaLake.OracleTablesLog
        where OracleRows < 10000000 AND OracleRows > 0 AND CountyFilter IS NOT NULL and PrimaryKeyColumn !=''
[2023-07-11T23:04:02.541+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.543+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.545+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.554+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.555+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.556+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.559+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.560+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead
  series = series.astype(t, copy=False)

[2023-07-11T23:04:02.575+0000] {SparkOracle2FileStore.py:83} INFO - Skipping log tables and reading tables directly
[2023-07-11T23:04:02.576+0000] {SparkOracle2FileStore.py:93} INFO - processing 1 out of 60
[2023-07-11T23:04:02.577+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.FLAG_TRACK
[2023-07-11T23:04:02.577+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-11T23:04:04.375+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.FLAG_TRACK
[2023-07-11T23:04:04.375+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-11T23:04:06.680+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-11T23:04:07.294+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-11T23:04:07.294+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-11T23:04:08.441+0000] {SparkOracle2FileStore.py:116} INFO - 6656
[2023-07-11T23:04:08.442+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-11T23:04:09.573+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/FLAG_TRACK
[2023-07-11T23:04:09.573+0000] {logging_mixin.py:149} INFO - Returning False
[2023-07-11T23:04:09.573+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-11T23:04:09.573+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
[2023-07-11T23:04:16.169+0000] {SparkOracle2FileStore.py:184} INFO - Table Processing complete for PR_LRS.FLAG_TRACK
[2023-07-11T23:04:16.285+0000] {SparkOracle2FileStore.py:93} INFO - processing 2 out of 60
[2023-07-11T23:04:16.286+0000] {logging_mixin.py:149} INFO - Attempting to get lowest value by column ID on table PR_LRS.OCAT
[2023-07-11T23:04:16.286+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-11T23:04:17.470+0000] {logging_mixin.py:149} INFO - Attempting to get max value by column ID on table PR_LRS.OCAT
[2023-07-11T23:04:17.470+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table by query...
[2023-07-11T23:04:18.699+0000] {logging_mixin.py:149} INFO - Attempting to read oracle table...
[2023-07-11T23:04:19.231+0000] {SparkOracle2FileStore.py:113} INFO - Filter Processor Disabled
[2023-07-11T23:04:19.231+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-11T23:04:20.753+0000] {SparkOracle2FileStore.py:116} INFO - 176399
[2023-07-11T23:04:20.754+0000] {logging_mixin.py:149} INFO - Attempting to read oracle rowcount by query...
[2023-07-11T23:04:22.060+0000] {logging_mixin.py:149} INFO - Checking if directory exists:/home/nicholas/dev/output/OCAT
[2023-07-11T23:04:22.060+0000] {logging_mixin.py:149} INFO - Returning True
[2023-07-11T23:04:22.060+0000] {SparkOracle2FileStore.py:178} INFO - Should not go in here if table dir exists
[2023-07-11T23:04:22.060+0000] {SparkOracle2FileStore.py:179} INFO - Overwriting table since ForceTable is enabled or directory does not exist, check logs
